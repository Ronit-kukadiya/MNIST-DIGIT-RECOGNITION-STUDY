{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# in this file we will try and implement the CNN_TF algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN:\n",
    "    def __init__(self, input_shape=(20, 20), num_classes=10, learning_rate=0.01):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        \"\"\" Xavier initialization for better training stability \"\"\"\n",
    "        self.conv1_filters = np.random.randn(3, 3, 1, 32) * np.sqrt(2 / (3 * 3 * 1))\n",
    "        self.conv1_bias = np.zeros((32,))\n",
    "        \n",
    "        self.conv2_filters = np.random.randn(3, 3, 32, 64) * np.sqrt(2 / (3 * 3 * 32))\n",
    "        self.conv2_bias = np.zeros((64,))\n",
    "        \n",
    "        self.fc1_input_size = 8 * 8 * 64\n",
    "        self.fc1_weights = np.random.randn(128, self.fc1_input_size) * np.sqrt(2 / self.fc1_input_size)\n",
    "        self.fc1_bias = np.zeros((128,))\n",
    "\n",
    "        self.fc2_weights = np.random.randn(self.num_classes, 128) * np.sqrt(2 / 128)\n",
    "        self.fc2_bias = np.zeros((self.num_classes,))\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def relu_derivative(self, x):\n",
    "        return (x > 0).astype(float)\n",
    "\n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "    def forward_pass(self, X):\n",
    "        \"\"\" Forward propagation through the network \"\"\"\n",
    "        X = X.reshape(-1, 20, 20, 1)\n",
    "\n",
    "        # Conv Layer 1\n",
    "        conv1_output = np.zeros((X.shape[0], 18, 18, 32))\n",
    "        for i in range(18):\n",
    "            for j in range(18):\n",
    "                region = X[:, i:i+3, j:j+3, :]\n",
    "                conv1_output[:, i, j, :] = np.tensordot(region, self.conv1_filters, axes=([1, 2, 3], [0, 1, 2])) + self.conv1_bias\n",
    "\n",
    "        conv1_output = self.relu(conv1_output)\n",
    "\n",
    "        # Conv Layer 2\n",
    "        conv2_output = np.zeros((conv1_output.shape[0], 16, 16, 64))\n",
    "        for i in range(16):\n",
    "            for j in range(16):\n",
    "                region = conv1_output[:, i:i+3, j:j+3, :]\n",
    "                conv2_output[:, i, j, :] = np.tensordot(region, self.conv2_filters, axes=([1, 2, 3], [0, 1, 2])) + self.conv2_bias\n",
    "\n",
    "        conv2_output = self.relu(conv2_output)\n",
    "\n",
    "        # Max Pooling (2x2)\n",
    "        pooled_output = conv2_output[:, ::2, ::2, :]\n",
    "        flat_output = pooled_output.reshape(pooled_output.shape[0], -1)  # Shape (batch_size, 4096)\n",
    "\n",
    "        # Fully Connected Layer 1\n",
    "        fc1_output = self.relu(np.dot(flat_output, self.fc1_weights.T) + self.fc1_bias)\n",
    "\n",
    "        # Fully Connected Layer 2 (Output)\n",
    "        logits = np.dot(fc1_output, self.fc2_weights.T) + self.fc2_bias\n",
    "        output = self.softmax(logits)\n",
    "\n",
    "        return output, flat_output, fc1_output\n",
    "\n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        \"\"\" Cross-entropy loss \"\"\"\n",
    "        m = y_true.shape[0]\n",
    "        log_likelihood = -np.log(y_pred[range(m), y_true])\n",
    "        return np.sum(log_likelihood) / m\n",
    "\n",
    "    def backward_pass(self, X, y_true, y_pred, flat_output, fc1_output, learning_rate):\n",
    "        \"\"\" Backpropagation and weight updates using SGD \"\"\"\n",
    "        m = y_true.shape[0]\n",
    "\n",
    "        # Compute gradients\n",
    "        d_logits = y_pred\n",
    "        d_logits[range(m), y_true] -= 1\n",
    "        d_logits /= m\n",
    "\n",
    "        # Gradients for fully connected layer 2\n",
    "        d_fc2_weights = np.dot(d_logits.T, fc1_output)\n",
    "        d_fc2_bias = np.sum(d_logits, axis=0)\n",
    "\n",
    "        d_fc1_output = np.dot(d_logits, self.fc2_weights)\n",
    "\n",
    "        # Gradients for fully connected layer 1\n",
    "        d_fc1_output *= self.relu_derivative(fc1_output)\n",
    "        d_fc1_weights = np.dot(d_fc1_output.T, flat_output)\n",
    "        d_fc1_bias = np.sum(d_fc1_output, axis=0)\n",
    "\n",
    "        # Weight updates using simple SGD\n",
    "        self.fc2_weights -= learning_rate * d_fc2_weights\n",
    "        self.fc2_bias -= learning_rate * d_fc2_bias\n",
    "\n",
    "        self.fc1_weights -= learning_rate * d_fc1_weights\n",
    "        self.fc1_bias -= learning_rate * d_fc1_bias\n",
    "\n",
    "    def fit(self, X_train, y_train, epochs=10, batch_size=128):\n",
    "        \"\"\" Training the model \"\"\"\n",
    "        start_time = time.time()\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(0, X_train.shape[0], batch_size):\n",
    "                X_batch = X_train[i:i+batch_size]\n",
    "                y_batch = y_train[i:i+batch_size]\n",
    "\n",
    "                # Forward Pass\n",
    "                y_pred, flat_output, fc1_output = self.forward_pass(X_batch)\n",
    "\n",
    "                # Compute Loss\n",
    "                loss = self.compute_loss(y_batch, y_pred)\n",
    "\n",
    "                # Backpropagation\n",
    "                self.backward_pass(X_batch, y_batch, y_pred, flat_output, fc1_output, self.learning_rate)\n",
    "\n",
    "                if i == 0:  # Print loss for the first batch of each epoch\n",
    "                    print(f\"Epoch {epoch+1}, Loss: {loss:.4f}\")\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(f\"Training completed in {round(end_time - start_time, 2)} seconds.\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred, _, _ = self.forward_pass(X)\n",
    "        return np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load Preprocessed Data (Cropped CSV)\n",
    "train_df = pd.read_csv(\"../2PREPROCESSING/Processed_CSV/cropped_train.csv\")\n",
    "test_df = pd.read_csv(\"../2PREPROCESSING/Processed_CSV/cropped_test.csv\")\n",
    "\n",
    "# Separate Features (X) and Labels (y)\n",
    "X_train, y_train = train_df.iloc[:, 1:].values, train_df.iloc[:, 0].values\n",
    "X_test, y_test = test_df.iloc[:, 1:].values, test_df.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.5359\n",
      "Epoch 2, Loss: 0.2803\n",
      "Epoch 3, Loss: 0.2191\n",
      "Epoch 4, Loss: 0.1882\n",
      "Epoch 5, Loss: 0.1666\n",
      "Epoch 6, Loss: 0.1489\n",
      "Epoch 7, Loss: 0.1342\n",
      "Epoch 8, Loss: 0.1220\n",
      "Epoch 9, Loss: 0.1108\n",
      "Epoch 10, Loss: 0.1009\n",
      "Training completed in 349.07 seconds.\n",
      "\n",
      "Test Accuracy: 0.9634\n",
      "Training Time: 349.07 seconds\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Train and Evaluate the Implemented CNN\n",
    "custom_cnn = CustomCNN(input_shape=(20, 20), num_classes=10)\n",
    "\n",
    "start_time = time.time()\n",
    "custom_cnn.fit(X_train, y_train, epochs=10, batch_size=128)\n",
    "end_time = time.time()\n",
    "\n",
    "y_pred_custom_cnn = custom_cnn.predict(X_test)\n",
    "\n",
    "# Compute Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_custom_cnn)\n",
    "print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Training Time: {round(end_time - start_time, 2)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this custom algorithm has accuracy of 96.34%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
